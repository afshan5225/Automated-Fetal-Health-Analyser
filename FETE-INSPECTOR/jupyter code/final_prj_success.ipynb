{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCA5-6y1qt5v"
      },
      "outputs": [],
      "source": [
        "! pip install -U spacy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mhu7kwwrGfz",
        "outputId": "776c6a0d-bfb5-4f42-bee1-1e680d6ff271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.7.5                         \n",
            "Location         /usr/local/lib/python3.10/dist-packages/spacy\n",
            "Platform         Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "Python version   3.10.12                       \n",
            "Pipelines        en_core_web_sm (3.7.1)        \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2UvkUPMtgpZ"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "db = DocBin() # create a DocBin object\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhNy58PmhRnf",
        "outputId": "6f1796de-83f5-4a65-f5db-6ecf22d7acdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9xf8RzPuFwU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "f = open(r\"/content/annotations (3).json\")\n",
        "TRAIN_DATA = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CBoQ3vTurwd",
        "outputId": "a714609b-8d93-4c19-e9ea-aacba52ec762"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classes': ['TRIMESTER',\n",
              "  'PLACENTA',\n",
              "  'LIQUOR',\n",
              "  'FETAL ACTIVITY',\n",
              "  'CARDIAC ACTIVITY',\n",
              "  'FETAL HEART BEAT',\n",
              "  'CROWN LUMP LENGTH',\n",
              "  'BIPARIETAL DIAMETER',\n",
              "  'HEAD CIRCUMFERENCE',\n",
              "  'ABDOMINAL CIRCUMFERENCE'],\n",
              " 'annotations': [['JAMM SCANS DEPARTMENT OF FETAL MEDICINE No:16 Vaidhyaraman Street Tnagar Patient name AgelSex 31 Years Female Patient ID Visit no Referred bY Visit date LMP date 02/03/2023 \\r\\n\\r\\nLMP EDD: 07/12/2023[12W 1DL OB 3\\r\\n\\r\\n First Trimester Scan Report Indication(s) First trimester screening \\r\\n\\r\\nReal time B-mode ultrasonography of gravid uterus done_ Route: Transabdominal and Transvaginal Single intrauterine gestation Medicalnotes \\r\\n\\r\\nBlood group AIB+ve Height 159 cms Weight : 48.2kgs Marital History : 4 years   Consanguinity : NCM Menstrual History Regular\\r\\n\\r\\n Gravida 2 Para 1 Live 1 Abortion : 0 Significant previous obstetric details Nil\\r\\n\\r\\n Medical Surgical History Lscs. Maternal Cervix measured 3.10 cm in length.\\r\\n\\r\\n Right Uterine 1.8 (57%) Left Uterine 1.4 FO+ (29%) Mean PI 1.6 F 3 (45%) Fetus Survey\\r\\n\\r\\n Placenta Anterior Liquor Normal \\r\\n\\r\\nFetal activity present \\r\\n\\r\\nCardiac activity present\\r\\n\\r\\n Fetal heart rate 154 bpm\\r\\n\\r\\n Biometry (mm) CRL 59, 12W 3D 14(54%)\\r\\n\\r\\n BPD 21, 13W 2D F+ ,4(81 %) \\r\\n\\r\\nHC 75.43,13W 1D F+4(65%)\\r\\n\\r\\n Ac 58.14, 12W 4D F+4(71%)\\r\\n\\r\\n PC PNDT 1284/2016 FOR APPOINTMENTS KINDLY CONTACT US AT 7904513421 7338771733 Page #1 26/05/23 11.29 AM ',\n",
              "   {'entities': [[214, 229, 'TRIMESTER'],\n",
              "     [819, 827, 'PLACENTA'],\n",
              "     [835, 841, 'LIQUOR'],\n",
              "     [919, 922, 'FETAL HEART BEAT'],\n",
              "     [949, 951, 'CROWN LUMP LENGTH'],\n",
              "     [976, 978, 'BIPARIETAL DIAMETER'],\n",
              "     [1006, 1015, 'HEAD CIRCUMFERENCE'],\n",
              "     [1035, 1040, 'ABDOMINAL CIRCUMFERENCE']]}]]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "TRAIN_DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1Ogqp0cuTMw",
        "outputId": "be435fe9-318b-4f10-fd6c-0777320bfb78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 74.29it/s]\n"
          ]
        }
      ],
      "source": [
        "for text, annot in tqdm(TRAIN_DATA['annotations']):\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents\n",
        "    db.add(doc)\n",
        "\n",
        "db.to_disk(\"./training_data.spacy\") # save the docbin object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xHbuio2uVhN",
        "outputId": "25219631-ebcf-4cfc-95a7-a7772f152b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: ner\n",
            "- Optimize for: efficiency\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "! python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEgWfmUavqD4",
        "outputId": "9cfa7d84-df94-4426-b339-0148dedf1422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    109.97    0.00    0.00    0.00    0.00\n",
            "200     200         35.73   2141.32  100.00  100.00  100.00    1.00\n",
            "400     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "600     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "800     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1000    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1200    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1400    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1600    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1800    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model-last\n"
          ]
        }
      ],
      "source": [
        "! python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZBxYJAEbRBO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fImxb8BXM3Px"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwqwrdObwytV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc3b0a8-f606-4012-df4a-ce3332e493b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ],
      "source": [
        "nlp_ner = spacy.load(\"/content/model-best\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import json\n",
        "\n",
        "# Load your trained model\n",
        "nlp = spacy.load(\"/content/model-best\")\n",
        "\n",
        "# Load evaluation data from JSON\n",
        "with open(\"/content/annotations (3).json\", \"r\") as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# Assuming your evaluation data structure is similar to the training data\n",
        "eval_annotations = evaluation_data['annotations']\n",
        "\n",
        "# Initialize variables to track evaluation metrics\n",
        "total_entities = 0\n",
        "correct_predictions = 0\n",
        "predicted_entities = 0\n",
        "\n",
        "# Iterate through each evaluation example\n",
        "for text, annot in eval_annotations:\n",
        "    # Process the text with the loaded NER model\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract predicted entities\n",
        "    predicted = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
        "\n",
        "    # Compare predicted entities with gold standard annotations\n",
        "    for start, end, label in annot['entities']:\n",
        "        total_entities += 1\n",
        "        if (start, end, label) in predicted:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    predicted_entities += len(predicted)\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = correct_predictions / predicted_entities if predicted_entities > 0 else 0\n",
        "recall = correct_predictions / total_entities if total_entities > 0 else 0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "# Set your desired minimum score threshold\n",
        "minimum_score = 0.90  # 90% threshold\n",
        "\n",
        "# Print evaluation scores\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "\n",
        "# Check against the minimum score threshold\n",
        "if precision >= minimum_score and recall >= minimum_score and f1_score >= minimum_score:\n",
        "    print(f\"\\n  model meets the minimum {minimum_score * 100:.0f}% score threshold.\")\n",
        "else:\n",
        "    print(f\"\\nYour model does not meet the minimum {minimum_score * 100:.0f}% score threshold. Further improvement may be needed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpZLaJfnbZal",
        "outputId": "2aa3ba7b-9b54-4f38-d980-033bb2016522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "\n",
            "  model meets the minimum 90% score threshold.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrI8vFLRbSAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bd4108-ae20-4de4-ab94-8b449b83c57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.4)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->easyocr)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->easyocr)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->easyocr)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->easyocr)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->easyocr)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->easyocr)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->easyocr)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.6.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Installing collected packages: pyclipper, ninja, python-bidi, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "Successfully installed easyocr-1.7.1 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pyclipper-1.3.0.post5 python-bidi-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "206RmwjPcUso",
        "outputId": "4acb20ab-196b-4b29-9f10-09995c40ce0e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e34af5d-8e0f-429a-8d68-ccf4ac2e3a07\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8e34af5d-8e0f-429a-8d68-ccf4ac2e3a07\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e2a6e87af827>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Access uploaded ima\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]  # Access uploaded ima\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5htgSFTtcaVm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilx5dhfCHEZA"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "reader = easyocr.Reader(['en'])  # Adjust language(s) as needed\n",
        "\n",
        "def extract_text_from_image(image_path):\n",
        "    text = reader.readtext(image_path, detail=1)\n",
        "    extracted_text = \"\"\n",
        "    for line in text:\n",
        "        extracted_text += line[1] + \" \"\n",
        "    return extracted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fcfgj4Zcl_O"
      },
      "outputs": [],
      "source": [
        "extracted_text = extract_text_from_image(image_path)\n",
        "\n",
        "print(extracted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkDwKp4qcqd9"
      },
      "outputs": [],
      "source": [
        "doc1 = nlp_ner(extracted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5qyXm8mxRpQ"
      },
      "outputs": [],
      "source": [
        "visualization_output = spacy.displacy.render(doc1, style=\"ent\", jupyter=True) # display in Jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ba1M24iL23qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYn8DoaNzcyR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuShVZZs0JfC"
      },
      "outputs": [],
      "source": [
        "gen = pd.DataFrame(visualization_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2mCUPV6fEXb"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"/content/model-best\")\n",
        "\n",
        "# Your paragraph of text\n",
        "paragraph = extracted_text\n",
        "# Process the paragraph with spaCy\n",
        "doc = nlp(paragraph)\n",
        "\n",
        "# Extract entities and their labels\n",
        "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "entity_dict = {entity[0]: entity[1] for entity in entities}\n",
        "\n",
        "# Output the dictionary\n",
        "print(entity_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgdQ4EE1JdYV"
      },
      "outputs": [],
      "source": [
        "def reverse_dict(entity_dict):\n",
        "    reversed_dict = {value: key for key, value in entity_dict.items()}\n",
        "    return reversed_dict\n",
        "\n",
        "reversed_dict = reverse_dict(entity_dict)\n",
        "print( reversed_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA1ltAvCQotf"
      },
      "outputs": [],
      "source": [
        "# Define the reference ranges for each parameter\n",
        "reference_ranges = {\n",
        "    \"TRIMESTER\": \"First Trimester Scan Report\",\n",
        "    \"PLACENTA\": \"Anterior\",\n",
        "    \"LIQUOR\": \"Normal\",\n",
        "    \"CARDIAC_ACTIVITY\": \"Cardiac activity present\",\n",
        "    \"FETAL_HEART_BEAT\": (110, 160),  # bpm\n",
        "    \"CROWN_LUMP_LENGTH\": (43, 60),  # mm\n",
        "    \"BIPARIETAL_DIAMETER\": (17, 42),  # mm\n",
        "    \"HEAD_CIRCUMFERENCE\": (60, 80),  # mm\n",
        "    \"ABDOMINAL_CIRCUMFERENCE\": (50, 60),  # mm\n",
        "}\n",
        "\n",
        "# Initialize a flag to track if all values are within range\n",
        "in_range = True\n",
        "\n",
        "# Simulated DataFrame iteration\n",
        "# for index, row in df.iterrows():\n",
        "#     entity = row[\"Entity\"]\n",
        "#     label = row[\"Label\"]\n",
        "\n",
        "# Simulating data for testing purposes\n",
        "data = entity_dict\n",
        "\n",
        "# Iterate over the keys and values of the reference ranges dictionary\n",
        "for label, reference_value in reference_ranges.items():\n",
        "    # Check if the extracted entity matches the reference value\n",
        "    if label in data:\n",
        "        entity = data[label]\n",
        "        if isinstance(reference_value, tuple):  # Check if it's a range\n",
        "            if not (reference_value[0] <= float(entity) <= reference_value[1]):\n",
        "                in_range = False\n",
        "                break\n",
        "        else:  # Check if it's a string\n",
        "            if entity != reference_value:\n",
        "                in_range = False\n",
        "                break\n",
        "\n",
        "# Output the result\n",
        "if in_range:\n",
        "    print(\"Fetus is in good condition\")\n",
        "else:\n",
        "    print(\"Fetus is not in good condition\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the reference ranges for each parameter\n",
        "reference_ranges = {\n",
        "    \"TRIMESTER\": \"First Trimester Scan Report\",\n",
        "    \"LIQUOR\": \"Normal\",\n",
        "    \"CARDIAC ACTIVITY\": \"present\",\n",
        "    \"FETAL HEART BEAT\": (110, 160),  # bpm\n",
        "    \"CROWN LUMP LENGTH\": (43, 60),  # mm\n",
        "    \"BIPARIETAL DIAMETER\": (17, 42),  # mm\n",
        "    \"HEAD CIRCUMFERENCE\": (60, 80),  # mm\n",
        "    \"ABDOMINAL CIRCUMFERENCE\": (50, 60),  # mm\n",
        "}\n",
        "\n",
        "# Simulated extracted data (reversed_dict in your case)\n",
        "#reversed_dict = {\n",
        "   # 'LIQUOR': 'Normal',\n",
        "    #'CARDIAC ACTIVITY': 'present',\n",
        "    #'FETAL HEART BEAT': '167',\n",
        "    #'CROWN LUMP LENGTH': '72',\n",
        "    #'BIPARIETAL DIAMETER': '25',\n",
        "    #'HEAD CIRCUMFERENCE': '86.43',\n",
        "    #'ABDOMINAL CIRCUMFERENCE': '69.14'\n",
        "#}\n",
        "\n",
        "# Initialize a flag to track if all values are within range\n",
        "in_range = True\n",
        "\n",
        "# Iterate over the keys and values of the reference ranges dictionary\n",
        "for label, reference_value in reference_ranges.items():\n",
        "    # Check if the extracted entity exists in the data\n",
        "    if label in reversed_dict:\n",
        "        entity = reversed_dict[label]\n",
        "        # Convert entity to float if it's numeric\n",
        "        try:\n",
        "            entity = float(entity)\n",
        "        except ValueError:\n",
        "            pass  # Handle non-numeric values gracefully\n",
        "\n",
        "        if isinstance(reference_value, tuple):  # Check if it's a range\n",
        "            if not (reference_value[0] <= entity <= reference_value[1]):\n",
        "                in_range = False\n",
        "                print(f\"{label}: {entity} is out of range {reference_value}\")\n",
        "        else:  # Check if it's a string\n",
        "            if entity != reference_value:\n",
        "                in_range = False\n",
        "                print(f\"{label}: {entity} is not {reference_value}\")\n",
        "    else:\n",
        "        in_range = False\n",
        "        print(f\"{label} is missing from the extracted data.\")\n",
        "\n",
        "# Output the result\n",
        "if in_range:\n",
        "    print(\"Fetus is in good condition\")\n",
        "else:\n",
        "    print(\"Fetus is not in good condition\")\n"
      ],
      "metadata": {
        "id": "MMTGEomKq4Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the reference ranges for each parameter\n",
        "reference_ranges = {\n",
        "    \"TRIMESTER\": \"2/3 Trimester Scan Report\",\n",
        "    \"PLACENTA\": \"Anterior\",\n",
        "    \"LIQUOR\": \"Normal\",\n",
        "    \"CARDIAC ACTIVITY\": \"present\",\n",
        "\n",
        "    \"FETAL HEART BEAT\": (120, 180),  # Heartbeat range in beats per minute\n",
        "    \"CROWN LUMP LENGTH\": (115, 400),  # Length in millimeters\n",
        "    \"BIPARIETAL DIAMETER\": (45, 88),  # Diameter in millimeters\n",
        "    \"HEAD CIRCUMFERENCE\": (160, 240),  # Circumference in millimeters\n",
        "    \"ABDOMINAL CIRCUMFERENCE\": (110, 190),  # Circumference in millimeters\n",
        "    \"TRANSVERSE CEREBELLAR DIAMETER\": (15, 25)  # Diameter in millimeters\n",
        "}\n",
        "\n",
        "# Simulated extracted data (replace with your actual data)\n",
        "\n",
        "\n",
        "# Initialize a flag to track if all values are within range\n",
        "in_range = True\n",
        "\n",
        "# Iterate over the keys and values of the reference ranges dictionary\n",
        "for label, reference_value in reference_ranges.items():\n",
        "    # Check if the extracted entity exists in the data\n",
        "    if label in reversed_dict:\n",
        "        entity = reversed_dict[label]\n",
        "        # Convert entity to float if it's numeric\n",
        "        try:\n",
        "            entity = float(entity)\n",
        "        except ValueError:\n",
        "            pass  # Handle non-numeric values gracefully\n",
        "\n",
        "        if isinstance(reference_value, tuple):  # Check if it's a range\n",
        "            if not (reference_value[0] <= entity <= reference_value[1]):\n",
        "                in_range = False\n",
        "                print(f\"{label}: {entity} is out of range {reference_value}\")\n",
        "        else:  # Check if it's a string\n",
        "            if entity != reference_value:\n",
        "                in_range = False\n",
        "                print(f\"{label}: {entity} is not {reference_value}\")\n",
        "    else:\n",
        "        in_range = False\n",
        "        print(f\"{label} is missing from the extracted data.\")\n",
        "\n",
        "# Output the result\n",
        "if in_range:\n",
        "    print(\"Fetus is in good condition\")\n",
        "else:\n",
        "    print(\"Fetus is not in good condition\")\n"
      ],
      "metadata": {
        "id": "558NuQaf1wGp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}